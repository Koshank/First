{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "traffic_data = pd.read_csv('traffic_data.csv')\n",
    "weather_data = pd.read_csv('weather_data.csv')\n",
    "calendar_data = pd.read_csv('calendar_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for numeric columns only\n",
    "traffic_data.fillna(traffic_data.select_dtypes(include=[float, int]).mean(numeric_only=True), inplace=True)\n",
    "weather_data.fillna(weather_data.select_dtypes(include=[float, int]).mean(numeric_only=True), inplace=True)\n",
    "calendar_data.fillna(calendar_data.select_dtypes(include=[float, int]).mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Alternatively, drop rows with missing values\n",
    "# traffic_data.dropna(inplace=True)\n",
    "# weather_data.dropna(inplace=True)\n",
    "# calendar_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data.drop_duplicates(inplace=True)\n",
    "weather_data.drop_duplicates(inplace=True)\n",
    "calendar_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data['timestamp'] = pd.to_datetime(traffic_data['timestamp'])\n",
    "weather_data['timestamp'] = pd.to_datetime(weather_data['timestamp'])\n",
    "calendar_data['timestamp'] = pd.to_datetime(calendar_data['timestamp'])\n",
    "traffic_data['vehicle_count'] = traffic_data['vehicle_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arora\\AppData\\Local\\Temp\\ipykernel_3900\\1695712791.py:3: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  traffic_data_hourly = traffic_data.resample('H').sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Resample traffic data to hourly intervals\n",
    "traffic_data.set_index('timestamp', inplace=True)\n",
    "traffic_data_hourly = traffic_data.resample('H').sum().reset_index()\n",
    "\n",
    "# Ensure data includes relevant details such as vehicle counts\n",
    "traffic_data_hourly = traffic_data_hourly[['timestamp', 'junction_id', 'vehicle_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Initialize scalers\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Normalize traffic data\n",
    "traffic_data_hourly[['vehicle_count']] = min_max_scaler.fit_transform(traffic_data_hourly[['vehicle_count']])\n",
    "\n",
    "# Alternatively, standardize traffic data\n",
    "# traffic_data_hourly[['vehicle_count']] = standard_scaler.fit_transform(traffic_data_hourly[['vehicle_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on the timestamp and junction_id\n",
    "data = pd.merge(traffic_data_hourly, weather_data, on='timestamp', how='left')\n",
    "data = pd.merge(data, calendar_data, on='timestamp', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "data['hour'] = data['timestamp'].dt.hour\n",
    "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "data['is_weekend'] = data['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "data['is_holiday'] = data['timestamp'].isin(calendar_data['timestamp']).astype(int)\n",
    "\n",
    "# Create lag features\n",
    "data['vehicle_count_lag1'] = data['vehicle_count'].shift(1)\n",
    "data['vehicle_count_lag2'] = data['vehicle_count'].shift(2)\n",
    "\n",
    "# Create moving averages\n",
    "data['vehicle_count_ma3'] = data['vehicle_count'].rolling(window=3).mean()\n",
    "\n",
    "# Drop rows with NaN values created by lag and rolling windows\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  junction_id  vehicle_count  temperature  \\\n",
      "2 2023-01-01 02:00:00            3       0.750000            5   \n",
      "3 2023-01-01 03:00:00            3       0.833333           -5   \n",
      "4 2023-01-01 04:00:00            3       0.861111           26   \n",
      "5 2023-01-01 05:00:00            3       0.638889           11   \n",
      "6 2023-01-01 06:00:00            3       0.805556           22   \n",
      "\n",
      "  weather_condition  is_holiday  hour  day_of_week  is_weekend  \\\n",
      "2              Rain           1     2            6           1   \n",
      "3              Snow           1     3            6           1   \n",
      "4              Snow           1     4            6           1   \n",
      "5              Snow           1     5            6           1   \n",
      "6              Snow           1     6            6           1   \n",
      "\n",
      "   vehicle_count_lag1  vehicle_count_lag2  vehicle_count_ma3  \n",
      "2            0.666667            0.472222           0.629630  \n",
      "3            0.750000            0.666667           0.750000  \n",
      "4            0.833333            0.750000           0.814815  \n",
      "5            0.861111            0.833333           0.777778  \n",
      "6            0.638889            0.861111           0.768519  \n"
     ]
    }
   ],
   "source": [
    "# Final preprocessed data\n",
    "preprocessed_data = data\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = preprocessed_data.drop(columns=['vehicle_count', 'timestamp', 'junction_id'])\n",
    "y = preprocessed_data['vehicle_count']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\arora\\Downloads\\archive (4)\\calendar_data.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
